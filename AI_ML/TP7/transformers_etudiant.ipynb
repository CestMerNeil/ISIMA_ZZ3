{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM45Gxq8KDOj"
   },
   "source": [
    "# Implémentation du réseau proposé dans l'article \"Attention is all you need\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 604,
     "status": "ok",
     "timestamp": 1692710290615,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "B1pv4CEUjirM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import LayerNormalization, Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFDaxVpKrCfj"
   },
   "source": [
    "## Calculer l'attention mise à l'échelle\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf A(\\mathbf X) = \\mathbf V(\\mathbf X).Softmax(\\frac{\\mathbf K(\\mathbf X)^T\\mathbf Q(\\mathbf X)}{\\sqrt{d_q}})\n",
    "\\end{equation*}\n",
    "\n",
    "On pourra utiliser les fonctions de tensorflow `matmul` et `softmax`. On retournera l'attention ainsi que les poids calculés par le softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1692710295237,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "m4yzYydXjs9T"
   },
   "outputs": [],
   "source": [
    "def AttentionEchelle(Q, K, V):\n",
    "    \"\"\"\n",
    "    Entrée :\n",
    "        Q -- requetes\n",
    "        K -- clés\n",
    "        V -- valeurs\n",
    "\n",
    "    Sortie :\n",
    "        A(X), Poids d'attention\n",
    "    \"\"\"\n",
    "\n",
    "    return A, poids_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq1Y_kHDGn8s"
   },
   "source": [
    "On donne une classe python pour coder un mécanisme d'attention multiple. H est le nombre de têtes, dim_e est la taille des représentations (embeddings), dq est la taille de Q et K, et dv la taille de V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1692710297859,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "HxTNI_MQjwEq"
   },
   "outputs": [],
   "source": [
    "class Multihead_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, H, dim_e, dq, dv):\n",
    "\n",
    "        super(Multihead_Attention, self).__init__()\n",
    "\n",
    "        #On initialisation des matrices de poids\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "        self.WQ = tf.Variable(initializer(shape=(H, dim_e, dq)), trainable=True)\n",
    "        self.WK = tf.Variable(initializer(shape=(H, dim_e, dq)), trainable=True)\n",
    "        self.WV = tf.Variable(initializer(shape=(H, dim_e, dv)), trainable=True)\n",
    "        self.WO = tf.Variable(initializer(shape=(H*dv,dim_e)), trainable=True)\n",
    "\n",
    "\n",
    "    # Calcul des poids d'attention : on utilise la fonction précédente\n",
    "    def call(self, Q, K, V):\n",
    "\n",
    "        Qh= np.dot(Q, self.WQ)\n",
    "        Kh= np.dot(K, self.WK)\n",
    "        Vh= np.dot(V, self.WV)\n",
    "\n",
    "        #Transposition\n",
    "        Qh=tf.transpose(Qh, [0,2,1,3])\n",
    "        Kh=tf.transpose(Kh, [0,2,1,3])\n",
    "        Vh=tf.transpose(Vh, [0,2,1,3])\n",
    "        Ah,_=AttentionEchelle(Qh, Kh, Vh)\n",
    "        A = tf.reshape(Ah,(Ah.shape[0],Ah.shape[2],Ah.shape[1]*Ah.shape[3]))\n",
    "        A= np.dot(A, self.WO)\n",
    "\n",
    "        return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Nn5Ow2EQuTi"
   },
   "source": [
    "On donne une classe implémentant un réseau complètement connecté. dim_e est la taille de l'embedding, dim_h la taille de la couche cachée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1692710301160,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "ofrxMmVaj3Sn"
   },
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim_e, dim_h):\n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = Conv1D(filters=dim_h, kernel_size=1,activation=\"relu\")\n",
    "        self.layer2 = Conv1D(filters=dim_e, kernel_size=1)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        x=self.layer1(x)\n",
    "        fnn_layer_out=self.layer2(x)\n",
    "\n",
    "\n",
    "        return fnn_layer_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag5vZhrwTcMX"
   },
   "source": [
    "On donne une classe permettant de précalculer une matrice contenant les encodages de position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1692710366336,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "moeCb0_oj7c9"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "\n",
    "    #Vecteur colonne contenant l'ensemble des positions de 0 à positions\n",
    "    pos=np.arange(positions)[:, np.newaxis]\n",
    "    #Vecteur ligne contenant les entiers de 0 à d-1 (dimensions)\n",
    "    k= np.arange(d)[np.newaxis, :]\n",
    "    i = k//2\n",
    "    #Matrice des angles\n",
    "    angles = pos/(10000**(2*i/d))\n",
    "\n",
    "    angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
    "    angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "\n",
    "    #Ajout d'un axe pour le traitement par batch\n",
    "    pos_encoding = angles[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYnvOSBKUfLX"
   },
   "source": [
    "## Construire l'encodeur comme spécifié dans la figure du cours.\n",
    "On donne le squelette de la classe à compléter. Ici :\n",
    "- H :nombre de têtes\n",
    "- dim_e: dimension de la représentation\n",
    "- dq : Taille de Q et K\n",
    "- dv : taille de V\n",
    "- dim_h : dimension de la couche cachée du MLP\n",
    "- eta : paramètre de régularisation de la couche de normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1692710308535,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "O5FL5wbUkL3t"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, H, dim_e, dq, dv, dim_h, layernorm_eta=1e-5):\n",
    "\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = Multihead_Attention(H, dim_e, dq, dv)\n",
    "        self.mlp = MLP(dim_e, dim_h)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eta)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eta)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        A compléter (figure du cours) : x est le tenseur de données, de taille (batch_size,N,dim_e).\n",
    "        En retour, on attend un tenseur de taille (batch_size,N,dim_e)\n",
    "        Attention, ne pas oublier les connexions résiduelles !!\n",
    "        \"\"\"\n",
    "        return encoder_layer_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-URz6A2X7gW"
   },
   "source": [
    "L'encodeur est un ensemble de K couches d'encodeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1692710311326,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "OTnYEM_bkP-Z"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, K, H, dim_e, dq, dv, dim_h,layernorm_eta=1e-6):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.layers=[EncoderLayer(H, dim_e, dq, dv, dim_h,layernorm_eta=layernorm_eta)\n",
    "                                  for i in range(K)]\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxr27TfEW3kX"
   },
   "source": [
    "## Faire le même travail pour le décodeur, en fonction de la figure du cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1692710314235,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "qokcWhPbkUKV"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, H, dim_e, dq, dv, dim_h,layernorm_eta=1e-6):\n",
    "\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = Multihead_Attention(H, dim_e, dq, dv)\n",
    "        self.mha2 = Multihead_Attention(H, dim_e, dq, dv)\n",
    "        self.mlp = MLP(dim_e, dim_h)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eta)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eta)\n",
    "        self.layernorm3 = LayerNormalization(epsilon=layernorm_eta)\n",
    "\n",
    "    def call(self, x, encoder_output):\n",
    "\n",
    "        \"\"\"\n",
    "        A compléter (figure du cours) :\n",
    "        x est le tenseur de données, de taille (batch_size,N,dim_e).\n",
    "        encoder_output est la sortie de l'encodeur\n",
    "        Attention, ne pas oublier les connexions résiduelles !!\n",
    "        \"\"\"\n",
    "\n",
    "        return decoder_layer_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QIMmytWYE7D"
   },
   "source": [
    "Le décodeur est un ensemble de K couches de décodeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1692710317033,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "iipGG1fEkW-y"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, K, H, dim_e, dq, dv, dim_h,  layernorm_eta=1e-6):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers=[DecoderLayer(H, dim_e, dq, dv, dim_h,layernorm_eta=layernorm_eta)\n",
    "                                  for i in range(K)]\n",
    "\n",
    "    def call(self, x, encoder_output, training=False):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,encoder_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gyruq2gYX6C"
   },
   "source": [
    "## Construire l'assemblage de l'encodeur et du décodeur pour produire le transformer.\n",
    "\n",
    "vous devez compléter la fonction call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1692710385079,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "aBO1FoE2kZfd"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, N, H, dim_e, dq, dv, dim_h,\n",
    "                 vocab_size, max_positional_encoding,\n",
    "                 layernorm_eta=1e-6):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        initializer = tf.keras.initializers.GlorotUniform()\n",
    "        self.embedding = tf.Variable(initializer(shape=(vocab_size, dim_e)), trainable=True)\n",
    "        self.PE = positional_encoding(max_positional_encoding, dim_e)\n",
    "        self.encoder = Encoder(N, H, dim_e, dq, dv, dim_h, layernorm_eta=layernorm_eta)\n",
    "        self.decoder = Decoder(N, H, dim_e, dq, dv, dim_h, layernorm_eta=layernorm_eta)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, x, y):\n",
    "        \"\"\"\n",
    "        A faire\n",
    "        \"\"\"\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CieqY1VTYzOR"
   },
   "source": [
    "## Pour vérifier que votre code fonctionne, on instantie le problème avec les valeurs données dans l'article,\n",
    "On affiche un résumé du transformer. Vous devez obtenir 44,116,480 paramètres entraînables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1945,
     "status": "ok",
     "timestamp": 1692710389704,
     "user": {
      "displayName": "Vincent Barra",
      "userId": "03796775931529965958"
     },
     "user_tz": -120
    },
    "id": "DvwfVA1kks6l",
    "outputId": "f199cbc5-964c-4351-da76-ac2a56538d4e"
   },
   "outputs": [],
   "source": [
    "N, H, dim_e, dq, dv, dim_h, vocab_size, T, batch_size = 6, 8, 512, 64, 64, 2048,29, 11,3\n",
    "\n",
    "transformer = Transformer(N, H, dim_e, dq, dv, dim_h, vocab_size, T)\n",
    "\n",
    "input_shape = (None, T,vocab_size)\n",
    "x = tf.random.uniform((batch_size, T, vocab_size))\n",
    "y =  tf.random.uniform((batch_size, T, vocab_size))\n",
    "\n",
    "pred = transformer(x,y)\n",
    "transformer.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPT8lykwpy5AGnjcUR8/Np5",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
